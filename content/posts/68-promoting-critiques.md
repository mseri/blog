---
title: "Lowering the barrier to feedback"
date: 2026-02-12T14:22:32+01:00
tags: ["ideas", "feedback"]
categories: ["Blog"]
---

[What's wrong with this idea?](https://www.jakeworth.com/posts/whats-wrong-with-this-idea/)
I was reading the linked blog post this morning, and it got me thinking about honest feedback.
A suggestion that I usually share with our students is to send their draft to those friends that are not afraid to give honest criticism, and ask them to be brutally honest on what they think about any part of the draft, clarifying that it will not be taken personally.

The hard part is the latter, but it is a good exercise to practice getting used to being criticized, and to learn how to separate the criticism from one's ego. After all

> people like being told they're clever, they like being told they're right. _\[[source](https://www.rnz.co.nz/national/programmes/saturday/audio/2019023013/professor-carl-bergstrom-living-with-ai)\]_

and the only way to get good feedback is taking a break from this and be ready to take the blow

While in my experience most people are usually not afraid to voice criticism, the barrier is massively lowered if you explicitly ask for it and explicitly welcome it.

This whole discussion also reminded me of a recent [breakthrough newsletter](https://markmanson.net/breakthrough/181-ai-betray), where Mark Manson (author of "The Subtle Art of Not Giving a F*ck") shared his experience with AI sycophancy and how he has gotten around it using the following prompt:

> Your goal is to help me deeply understand a recent challenge or failure and extract the most valuable lessons from it. You will guide me one question at a time, asking only what is essential to uncover key insights.

I am not sure if this is mostly a result of being trained on massive amounts of stolen human data or if it is mostly a strategy to hook users in using positive reinforcement. But it is interesting to keep it in mind when using AI tools as sounding boards.

UPDATE: After listening to this [short and insightful interview with C. T. Bergstrom](https://www.rnz.co.nz/national/programmes/saturday/audio/2019023013/professor-carl-bergstrom-living-with-ai), I had to come back and edit this post. He gives an even more realistic reason for sycophancy. In reinforcement learning with human feedback (RLHF) people are chatting with the bots and selecting the responses they like most. People like to be praised. So the outcome should not be too surprising... Listen to the full interview, it is short and really worth it.
