---
title: "AI in Education - Some food for thought"
date: 2025-07-29T08:38:51+02:00
tags: [ai, education]
categories: ["Blog"]
---

What are we supposed to do about GenAI in (mathematical) education?
Many of us have been wrestling with it over the past few months. I certainly don't have a definitive answer, but it's a topic that demands we share what we're thinking and what we're seeing. If anything, it may bring a felt and needed opportunity to finally be able to rethink and reshape the way our education is organized. We discussed this in less uncertain times both in [It's Not Just Numbers](https://creators.spotify.com/pod/profile/not-just-numbers/episodes/S1E03---Teaching-mathematics--with-Tams-Grbe-and-Ceclia-Salgado-e2bsae3) and [various](https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S2-Ep9---Specifications-Grading-e2oida7) [episodes](https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S3E01-Critical-Pedagogy-and-the-Work-of-Paulo-Freire-e2oid9u) of [Degrees of Freedom](https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S3E06---Ungrading-e2oidaq), our podcasts on mathematics and education respectively.

It helps to start with a realistic view of the technology. I like Andrej Karpathy's take on it: think of using an AI less like consulting an oracle and more like "asking the average data labeler on the internet." That framing cuts through a lot of the hype and re-grounds the conversation: these are statistical models trained by imitation, not logical reasoning machines.

As you probably know, if you follow this rarely updated blog or if you follow me on social networks, I've been tinkering with these tools for quite a while. With time I settled to simple, tedious tasks where I can easily spot if something is wrong: generating ALT text for an image, getting a first draft of some Python code translated to JavaScript for a web demo, drawing pages for our kids, things like that... Itâ€™s a utility, a shortcut for boring work I could do myself and that I can easily check.

The real difficulty comes when we think about our classes and the use most of our stdents seem to be engaging with. Recently, I've started seeing homework submissions with what, citing a couple of colleagues, we often call "froofs": things that look a lot like proofs, using the right words and symbols, but are fundamentally flawed or nonsensical. What worries me isn't really that the answer is wrong, but that the entire process of mathematical thinking has been bypassed. The struggles, the dead ends, the (smaller and larger) breakthroughs, those are where the learning happens. A slick, confidently incorrect "froof" robs a student of that entire experience and, worse of all, of the learning itself.

By this I don't want to say, a priori, that these are bad and useless tools. As a user myself, I disagree with that. This is also not to ignore the many ethical and environmental issues that come with the technology (what is worse is that they seem to have shadowed the similar discussion concerning cryptocurrencies instead of joining the club and increasing the societal pressure), but I think it is fool to believe that these tools are not here to stay, perhaps resized, once the hype fades, hopefully less ubiquitous, and way cheaper and less energy-hungry to run.

But let's close this side note and go back to the original point. I did have also positive experiences, with students using the tools to generate new exercises that they could work on, and check the correctness of. These have been good way for them to test their understanding and formulate clearer questions to ask to me in class or at tutorials. So there are, after all, useful ways to integrate these tools in learning. And you may already have played with them yourselves, and realized this.

I have been pondering a lot how could I rethink my courses to try and benefit from the situation. I'm not interested in an arms race of AI detection; it feels like a losing battle and a miserable way to interact with students. This semester, I'm trying an experiment: I've made homework ungraded. The idea is to lower the stakes and, hopefully, remove the incentive to get the perfect answer, allowing more scope for exploration and feedback. The goal is for homework to be a place for genuine practice. We then use class and tutorial time for peer-feedback, which I hope encourages them to engage with the material and each other's reasoning more critically. The actual assessments of understanding are moved fully to the midterm and final exams.

I don't know if this is the "right" answer. It's just one attempt to adapt to a new reality. It feels more productive than simply banning the tools or pretending they don't exist. But it's an open question, and I suspect there are many different approaches being tried out there.

To share a couple of ideas from my colleagues, some are requesting students to explicitly sign pledges to not use LLMs or, at least, to detail how they used them in their work. The hope is at least to make students reflect on their use of these tools and, maybe, its implications, while also making it clearer that they are expected to engage with the material themselves. This also opens up an interesting conversation about academic integrity and cheating, but it is a rabbit hole I don't want to go down right now.

Others, more expert machine learning researchers, are using the internal design of LLMs to their advantage, rewriting their homework with paraphrases and keywords from popular culture, like character names and scenes from cult movies or famous TV shows, that are predominantly found on movie reviews rather than on STEM exercises. This way, they make it harder for students to simply copy-paste answers from LLMs or the web, while also making the homework more engaging and fun. LLMs are very sophisticated statistical parrots after all, and specific names and references steer them immediately away to specific bubbles of information (movies and TV shows in this case, rather than solutions of STEM exercises). This is a clever way to use the limitations of the technology to our advantage, and it also makes the homework way more enjoyable for students. Of course, the big caveat is that this requires a lot of effort to design the homework, and it may not be feasible for all courses or all instructors.

What are others trying? How are these tools showing up in your classrooms? I'm genuinely curious to hear other experiences and ideas. In the meantime I have collected my thoughts, experiences and experiments in a set of slides that we used to start the discussion at our department. I share them below since a few colleagues have been asking for them. Please, feel free to contact me to share your experiences!

{{< pdfreader url="attachments/25.06.08-AI_in_class.pdf" height="400px" >}}
