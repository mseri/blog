---
title: "UnAI Education?"
date: 2025-10-01T17:27:29+02:00
tags: [ai, education]
categories: ["Blog"]
---

I think an update on my previous blog post on [generative AI in education]({{< relref "61-AI-in-education.md" >}}) is in order. The discussion has been evolving, I am starting to see early signs of polarization, and a mix of denial and overly enthusiastic adoption. Ethical considerations, which had been largely ignored for a good while, are finally getting an increasingly relevant role if not in the decision making, at least in the reflections from many academics. And experimentation is picking up, starting to provide some clarity on the ups and downs of the current revolution.

*But is it really a revolution?* I can see the disruption, perhaps the fear and unrest that come from a novel hyped thing that is not fully understood yet and that we are not used to. But I don't really see a revolution, at least in the sense of something that would fundamentally change the way we do things.

The key question is probably: what is education and what is its purpose? I don't have a final answer and I don't know if there is a universal truth to this. We have debated this many times in our podcast Degrees of Freedom. While this came up in almost every episode, I'd recommend you to jump directly to these three: [3.5 What is the purpose of higher education](https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S3E05-Groningen-Podcasters-United---Whats-the-purpose-of-Higher-Education-e2oidal/a-abhk91h), [3.1 Critical pedagogy](https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S3E01-Critical-Pedagogy-and-the-Work-of-Paulo-Freire-e2oid9u), [1.1 What is the point of University education](https://creators.spotify.com/pod/profile/degrees-of-freedom/episodes/S1-Ep1---Whats-the-point-of-University-education-e2oida4/a-abhk910).

But I think we can agree on a few things, particularly that, with very few exceptions, education is a social activity. And it works at its best when you are surrounded by other like-minded learners, have access to an open and engaging teacher, and have plenty of space and time to talk. And this is probably why a real revolution in teaching has never really happened.

I was pleasantly surprised to hear the same kind of reflection in a [recent talk by Veritasium at the Perimeter Institute](https://youtu.be/0xS68sl2D70), that prompted me to write this post. But I found what he said next even more interesting, and admittedly this was a connection that I had failed to make yet:

> **I think that the tech hype comes from a place of believing that the problem of education is not being able to get the information to the student.
> That's not the problem.** It's not the problem now, and it wasn't the problem 100 years ago.
> When you have books, I mean, the information is all there. Assuming people have access, the students have access to those books. And yet they're probably not going to learn very much unless they have a great teacher, unless they have a group of like minded peers to go through that with them, unless they have a reason to do it.

If you are interested in education, I would recommend you to watch the full talk, question time included. It is really worth it.

I think the point he makes should be kept firmly in the back of our minds when we think about generative AI in education. Artificial intelligence could provide new tools to access information faster or to get help with specific boring tasks, but mostly (if not only) when you already know what you are talking about and can critically reflect on the output. And it cannot replace the social aspect of education: the interaction with peers and teachers and the motivation that comes from being part of a learning community.

I was recently reading about the difference between social networks and social media, and it felt like a similar story: it all started with social networks, an asynchronous way to connect with people, but then evolved into social media, a passive, never-ending consumption of content, leveraging dopamine to hook users into a black hole of barely meaningful information. And now instead of being more connected, we are more isolated (and sad) than ever.

We should not make the same mistake to turn generative AI in education into a passive consumption of content.

After all, learning happens and becomes internalized when we put in the effort, work through things slowly, fail and get unstuck, even better if we do this together. So, whatever we do, this has to remain paramount. Which was also one of the main points in the [previous post]({{< relref "61-AI-in-education.md" >}}) and is also an important point in the talk by Veritasium:

> I think about teachers a little bit like personal trainers. Like the gyms are there, but unless there's someone who you're going to and you're meeting there and you're held accountable to. And someone to say, "Another one and another, give me another rep. Keep going [...]". Someone to tell you the homework and someone to hold you accountable and someone to really energize you, and maybe a group of other people who are doing it at the same time and we're all like going to this together. That's when you see results.

We stand at a crossroads. We can let AI in education follow the same path as social media: turning what should be active, social engagement into passive consumption. Or we can choose a different path: using AI as a tool while keeping the social, effortful nature of learning at the center. We can also outright ban it. The choice is ours, but we need to make it consciously and soon, before the momentum of *progress and efficiency* makes it for us.

At the moment, I see more and more of this push to blindly adopt generative AI at universities. But there is a positive growing pushback. And don't get me wrong, as a heavy user of AIs, I prefer to avoid a blanket ban. But I firmly believe that *we cannot simply accept it uncritically*. And I was recently happily surprised to see that a group of academics, including a colleague at our university, have argued for this in an open letter: [**Stop the Uncritical Adoption of AI Technologies in Academia**](https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0).

At the time of writing this post, it contains 1,348 signatures. You may consider this a minority, but given the inertia of academics and the fact that many are largely unaware of this letter, I think this is already a significant number. Have a read, it is worth it, and if you agree with enough of it, consider signing it.

Of course there are plenty of other voices that argue for the opposite, but I think this is an important step to [have a balanced discussion](https://mindwise-groningen.nl/inviting-thoughts-about-ai-in-education/). And it is important also to avoid ignoring the critical evidence that is already available, and overshadowed by the hype and marketing campaigns: you can find a good collection of resources in this [Critical AI page](https://olivia.science/ai).

So, is generative AI in education really a revolution? I don't think so. At least not in the way that matters most. The real revolution would be finally recognizing that education is fundamentally about human connection, struggle, and growth, and start actively defending these principles. Generative AI can become a useful tool in this process, but only if we resist the temptation to let it replace what makes learning truly transformative: the messy, social, deeply human experience of learning together.

- - - - -

As an aside, let me address one of the ethical concerns we are facing when accepting the use of LLMs: the *massive intellectual property infringement that is happening when these models are trained on copyrighted material without permission*. This goes directly against the basic principles of academic integrity and respect for authorship and intellectual credit.

Thankfully, an increasing number of *fully open models* are becoming available, and I think we should push for these. Just recently, Allen AI released [OlmoE](https://allenai.org/language-models) and [Olmo2](https://allenai.org/olmo), and Switzerland released [Apertus](https://www.swiss-ai.org/apertus). For these models, everything, including the full training data and code, is available for scrutiny. IBM's [Granite 4.0](https://www.ibm.com/new/announcements/ibm-granite-4-0-hyper-efficient-high-performance-hybrid-models) models, while not so open, are also taking care of erhically crafting data and observing higher standards than many of the competitors. This is a step in the right direction, and I hope we will see more of it.

These are also relatively small models, and while they are not as powerful as other commercial solutions, they are already useful for many of the boring, repetitive tasks that we want to offload to some artificial intelligence. And they can be run on local machines, which is a big plus for privacy and data protection, while also partially limiting their environmental impact.
